{"url_slug": "1f14dc28fca920a998814000a6a82ec8fe8aeef6", "url": "https://pinboard.in/url:1f14dc28fca920a998814000a6a82ec8fe8aeef6", "pin_url": "http://ruder.io/optimizing-gradient-descent/", "user_list": ["DevJac", "barbaricbarbarella", "notiv", "abiola", "haraball", "amitp", "peerst", "gallatindemocrats", "tobym", "mrjdomingus", "owenrh", "pacopistola", "foodbaby", "kejadlen", "edgaron", "drmeme", "mdiarra", "sburer", "kdrath", "iewaij", "leifur", "hustwj", "jseppanen", "skchrko", "peerlessdeepak", "geetarista", "gregonicus", "kristjansson", "fuzzydata", "benjaminfjones", "nharbour", "linearpup", "jakubsvehla", "mike", "alexfikl"], "user_list_length": 35, "all_tags": ["adam", "algorithms", "blog", "data_science", "deep-learning", "deeplearning", "descent", "dl", "gradient-descent", "gradient", "gradientdescent", "gradient_descent", "linearalgebra", "links", "machine-learning", "machinelearning", "machine_learning", "math", "mathematics", "ml", "neuralnets", "neuralnetworks", "numerical-methods", "numerical", "optimisation", "optimization", "optimizer", "orms", "overview", "programming", "reference", "reinforcement-learning", "rmsprop", "sebastian-ruder", "sgd", "survey", "tensorflow", "training", "tutorial", "unorganized", "wp"], "url_slug_fetch_date": "2023-06-06T08:10:30.276982"}
